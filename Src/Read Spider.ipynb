{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate tables.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Define a function to load JSON data from a file\n",
    "def loadJson(filename):\n",
    "    # Open the specified file in read mode, specifying utf-8 encoding\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        # Load the JSON data from the file into a Python dictionary\n",
    "        data = json.load(file)\n",
    "    # Return the loaded data\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def fetchSpecificColumnForDbId(df, specificDbId, columnName):\n",
    "    # Filter rows based on the specific db_id\n",
    "    filteredDf = df[df['db_id'] == specificDbId]\n",
    "\n",
    "    # Extract the specified column from the filtered DataFrame\n",
    "    column_data = filteredDf[columnName]\n",
    "\n",
    "    # Convert the column data to a list\n",
    "    column_list = column_data.tolist()\n",
    "\n",
    "    return column_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTableDict(database):\n",
    "    dictWithTables = {}\n",
    "    # Extract table names from the database schema (assuming they are stored in 'table_names')\n",
    "    tablesNames = database['table_names']  # TODO: Change to 'table_names_translated' once available\n",
    "    \n",
    "    # Iterate over the table names and assign each a unique index as the key in the dictionary\n",
    "    for index, tableName in enumerate(tablesNames):\n",
    "        dictWithTables[index] = tableName\n",
    "    \n",
    "    return dictWithTables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def removeTextInParentheses(inputString):\n",
    "    # Define a regex pattern to match text within parentheses\n",
    "    pattern = r'\\([^)]*\\)'\n",
    "    \n",
    "    # Use re.sub() to replace the matched pattern with an empty string\n",
    "    outputString = re.sub(pattern, '', inputString)\n",
    "    \n",
    "    return outputString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import Client\n",
    "\n",
    "def meltemiTranslateInfo(prompt, modelName):\n",
    "  client = Client(host='http://10.8.11.209:11434')\n",
    "  response = client.chat(model= modelName, messages=[\n",
    "    {\n",
    "      'role': 'user',\n",
    "      'content': prompt\n",
    "    },\n",
    "  ])\n",
    "  return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def gptTranslateInfo(systemContent, inputInfo): \n",
    "    openai.api_base = 'https://pta-nbg-poc1.openai.azure.com/'\n",
    "    openai.api_key = '89423897cfd94a89838586e836d26690'\n",
    "    deployment_name = 'got-35-turbo1'\n",
    "    openai.api_type = 'azure'\n",
    "    openai.api_version = '2023-03-15-preview' # this may change in the future\n",
    "\n",
    "    # systemContent = '''I will give you english column names from tables in english and you will translate it in greek. \n",
    "    # Please return only the translated column.'''\n",
    "\n",
    "    # inputInfo = '''Translate the column \"assets in million\" to greek to fit the context of the table:\n",
    "    # Table: company\n",
    "    # Columns: company id, name, headquarters, industry, sales in million, assets in million'''\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=deployment_name, # The deployment name you chose when you deployed the GPT-3.5-Turbo or GPT-4 model.\n",
    "        temperature=0.3,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": systemContent},\n",
    "            {\"role\": \"user\", \"content\": inputInfo}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollamaModels = ['meltemiUpdated', 'llama3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['column_names', 'column_names_original', 'column_types', 'db_id', 'foreign_keys', 'primary_keys', 'table_names', 'table_names_original'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the tables.json\n",
    "tableFileName = r'..\\Spider\\tables.json'\n",
    "tablesData = loadJson(tableFileName)\n",
    "tablesData[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "listWithDbId = []\n",
    "listWithTableNameOriginalPerDbId = []\n",
    "\n",
    "# Iterate over each database in tablesData\n",
    "for database in tablesData:\n",
    "    # Extract the db_id of the current database\n",
    "    dbId = database['db_id']\n",
    "    # Extract the table_names_original from the current database\n",
    "    tableNamesOriginal = database['table_names_original']\n",
    "    \n",
    "    # Iterate over each tableNameOriginal in tableNamesOriginal\n",
    "    for tableNameOriginal in tableNamesOriginal:\n",
    "        # Append the dbId to listWithDbId\n",
    "        listWithDbId.append(dbId)\n",
    "        # Append the tableNameOriginal to listWithTableNameOriginalPerDbId\n",
    "        listWithTableNameOriginalPerDbId.append(tableNameOriginal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/876 of table names examined.\n"
     ]
    }
   ],
   "source": [
    "dictWithTranslatedTableName = {}\n",
    "\n",
    "systemContent = 'I will give you table names from a schema in english and you will translate it to greek. Please return only the translated table name.'\n",
    "\n",
    "totalNumOfTableNames = len(listWithTableNameOriginalPerDbId)\n",
    "tenPercent = totalNumOfTableNames // 100  # Calculate 1% of the total tables\n",
    "\n",
    "# Iterate over each tableName in listWithTableNameOriginalPerDbId\n",
    "for index, tableName in enumerate(listWithTableNameOriginalPerDbId, start=1):\n",
    "    # Call the function to translate the tableName\n",
    "    gptTranslatedTableName = removeTextInParentheses(gptTranslateInfo(systemContent, tableName))\n",
    "    if 'Gpt' not in dictWithTranslatedTableName.keys():\n",
    "        dictWithTranslatedTableName['Gpt'] = [gptTranslatedTableName]\n",
    "    elif 'Gpt' in dictWithTranslatedTableName.keys():\n",
    "        dictWithTranslatedTableName['Gpt'].append(gptTranslatedTableName)\n",
    "    \n",
    "    for ollamaModelName in ollamaModels:\n",
    "        ollamaTranslatedTableName = removeTextInParentheses(meltemiTranslateInfo(f'{systemContent} \\n {tableName}', ollamaModelName))\n",
    "        if ollamaModelName not in dictWithTranslatedTableName.keys():\n",
    "            dictWithTranslatedTableName[ollamaModelName] = [ollamaTranslatedTableName]\n",
    "        elif ollamaModelName in dictWithTranslatedTableName.keys():\n",
    "            dictWithTranslatedTableName[ollamaModelName].append(ollamaTranslatedTableName)\n",
    "    \n",
    "    # Check if approximately 10% of tables have been examined\n",
    "    if index % tenPercent == 0:\n",
    "        print(f\"{index}/{totalNumOfTableNames} of table names examined.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Gpt': ['Δράστης',\n",
       "  'άνθρωποι',\n",
       "  'αίθουσα διδασκαλίας',\n",
       "  'τμήμα',\n",
       "  'μάθημα',\n",
       "  'καθηγητής',\n",
       "  'τμήμα',\n",
       "  'διδάσκει'],\n",
       " 'meltemiUpdated': ['perpetrator ',\n",
       "  'Πίνακας: άνθρωποι \\n\\nΜεταφρασμένο σε Ελληνικά: Άνθρωποι ',\n",
       "  'classroom  = αίθουσα διδασκαλίας',\n",
       "  'τμήμα',\n",
       "  'Πρόγραμμα σπουδών ',\n",
       "  'instructor ',\n",
       "  'Είσαι ένας βοηθός που βοηθά τους ανθρώπους να βρίσκουν πληροφορίες. Θα σας δώσω μια αγγλική πρόταση και θα μεταφράσετε σε ελληνικά. Παρακαλώ απαντήστε μόνο με τη μετάφραση, χωρίς καμία εξήγηση ή πρόσθετες πληροφορίες.',\n",
       "  'Ελληνικά: Διδάσκει '],\n",
       " 'llama3': ['Εγκληματίας ',\n",
       "  'Λαοί\\n\\n',\n",
       "  'Ταξινόμος Classroom ',\n",
       "  'Τμήμα ',\n",
       "  'Πρόγραμμα ',\n",
       "  'Επιμελητής ',\n",
       "  'Εκτομή ',\n",
       "  'Εκδίδωσ ']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictWithTranslatedTableName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame has been written to Table Translate Evaluation.xlsx successfully.\n"
     ]
    }
   ],
   "source": [
    "tablesDf = pd.DataFrame(dictWithTranslatedTableName)\n",
    "# Add prefix to column names\n",
    "prefix = 'table_names_translated_'\n",
    "tablesDf.columns = [prefix + col for col in tablesDf.columns]\n",
    "\n",
    "tablesDf['db_id'] = listWithDbId[:8] # TODO Remove the limit\n",
    "tablesDf['table_names_original'] = listWithTableNameOriginalPerDbId[:8] # TODO Remove the limit\n",
    "tablesDf['table_names_translated'] = ''\n",
    "\n",
    "# Define the new column order with \"db_id\" first and \"table_names_original\" second\n",
    "newColumnOrder = ['db_id', 'table_names_original'] + [col for col in tablesDf.columns if col not in ['db_id', 'table_names_original']]\n",
    "\n",
    "# Change the order of columns using reindex\n",
    "tablesDf = tablesDf.reindex(columns=newColumnOrder)\n",
    "\n",
    "# Define the output file name for the Excel file\n",
    "tableOutputFileName = 'Table Translate Evaluation.xlsx'\n",
    "\n",
    "# Write the DataFrame to an Excel file without including the index\n",
    "tablesDf.to_excel(tableOutputFileName, index=False)\n",
    "\n",
    "# Print a confirmation message indicating successful writing of the DataFrame to the Excel file\n",
    "print(f\"DataFrame has been written to {tableOutputFileName} successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating a DataFrame with three columns: db_id, table_names_original, and table_names_translated\n",
    "# tablesDf = pd.DataFrame({\n",
    "#     'db_id': listWithDbId,\n",
    "#     'table_names_original': listWithTableNameOriginalPerDbId,\n",
    "#     'table_names_translated': listWithTranslatedTableName\n",
    "# })\n",
    "\n",
    "# # Define the output file name for the Excel file\n",
    "# tableOutputFileName = 'Table Translate Evaluation.xlsx'\n",
    "\n",
    "# # Write the DataFrame to an Excel file without including the index\n",
    "# tablesDf.to_excel(tableOutputFileName, index=False)\n",
    "\n",
    "# # Print a confirmation message indicating successful writing of the DataFrame to the Excel file\n",
    "# print(f\"DataFrame has been written to {tableOutputFileName} successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the final table name DataFrame from the Excel file\n",
    "tablesDf = pd.read_excel(tableOutputFileName)\n",
    "\n",
    "# Add the translated table names to the original data\n",
    "for database in tablesData:\n",
    "    # Extract the db_id of the current database\n",
    "    dbId = database['db_id']\n",
    "    # Fetch the translated table names for the current db_id from tablesDf\n",
    "    translated_table_names = fetchSpecificColumnForDbId(tablesDf, dbId, 'table_names_translated')\n",
    "    # Assign the translated table names to the 'table_names_translated' key in the original database data\n",
    "    database['table_names_translated'] = translated_table_names\n",
    "    break #TODO: Remove the break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the tables.json as it contains the translated table_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "listWithDbId = []\n",
    "listWithColumnNameOriginalPerDbId = []\n",
    "listWithTableIdForColumnName = []\n",
    "listWithTableNamesForColumnName = []\n",
    "\n",
    "# Iterate over each database in tablesData\n",
    "for database in tablesData:\n",
    "    # Extract the db_id of the current database\n",
    "    dbId = database['db_id']\n",
    "\n",
    "    # Create a dictionary of tables with their indices as keys\n",
    "    dictWithTables = createTableDict(database)\n",
    "    \n",
    "    # Iterate over each columnNameInfo in column_names_original of the current database\n",
    "    for columnNameInfo in database['column_names_original']:\n",
    "\n",
    "        # Append the dbId to listWithDbId\n",
    "        listWithDbId.append(dbId)\n",
    "        \n",
    "        # Extract the columnNameOriginal from columnNameInfo and append it to listWithColumnNameOriginalPerDbId\n",
    "        columnNameOriginal = columnNameInfo[1]\n",
    "        listWithColumnNameOriginalPerDbId.append(columnNameOriginal)\n",
    "        \n",
    "        # Extract the tableId from columnNameInfo and append it to listWithTableIdForColumnName\n",
    "        tableId = columnNameInfo[0]\n",
    "        listWithTableIdForColumnName.append(tableId)\n",
    "\n",
    "        # If tableId is -1, append '-1' to listWithTableNamesForColumnName, indicating unknown table\n",
    "        if tableId == -1:\n",
    "            listWithTableNamesForColumnName.append('-1')\n",
    "        else:\n",
    "            # Otherwise, append the table name corresponding to tableId to listWithTableNamesForColumnName\n",
    "            listWithTableNamesForColumnName.append(dictWithTables[tableId])\n",
    "    \n",
    "    # Remove the break to iterate over all databases\n",
    "    break #TODO: Remove the break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictionary to store table names as keys and corresponding column names as values.\n",
    "dictWitnTablesAndColumnsNames = {}\n",
    "\n",
    "# Iterate through pairs of table names and column names.\n",
    "for tableName, columnName in zip(listWithTableNamesForColumnName, listWithColumnNameOriginalPerDbId):\n",
    "    # Check if the table name is not already in the dictionary.\n",
    "    if tableName not in dictWitnTablesAndColumnsNames.keys():\n",
    "        # If not, initialize the entry with a list containing the current column name.\n",
    "        dictWitnTablesAndColumnsNames[tableName] = [columnName]\n",
    "    else:\n",
    "        # If the table name is already in the dictionary, append the current column name to its list of column names.\n",
    "        dictWitnTablesAndColumnsNames[tableName].append(columnName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTheDesiredPromtForColumnsTranslation(tableName, dictWitnTablesAndColumnsNames, columnName):\n",
    "    # Retrieve the list of column names associated with the given table name.\n",
    "    columnsInfo = dictWitnTablesAndColumnsNames[tableName]\n",
    "\n",
    "    # Join the list of column names into a comma-separated string.\n",
    "    columnCombination = ', '.join(columnsInfo)\n",
    "    \n",
    "    # Construct and return the prompt string for translating the given column name to Greek.\n",
    "    return f'''Translate the column \"{columnName}\" to Greek to fit the context of the table:\n",
    "            Table: {tableName}\n",
    "            Columns: {columnCombination}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictWithTranslatedColumnName = {}\n",
    "\n",
    "systemContent = 'I will give you english column names from tables and you will translate it to greek. Please return only the translated column.'\n",
    "\n",
    "count = 0 # TODO Remove Count\n",
    "# Iterate over each columnName in listWithColumnNameOriginalPerDbId\n",
    "for tableName, columnName in zip(listWithTableNamesForColumnName, listWithColumnNameOriginalPerDbId):\n",
    "    # Otherwise, call the function to translate the columnName\n",
    "    prompt = createTheDesiredPromtForColumnsTranslation(tableName, dictWitnTablesAndColumnsNames, columnName)\n",
    "    \n",
    "    gptTranslatedColumnName = removeTextInParentheses(gptTranslateInfo(systemContent, prompt))\n",
    "    if 'Gpt' not in dictWithTranslatedColumnName.keys():\n",
    "        dictWithTranslatedColumnName['Gpt'] = [gptTranslatedColumnName]\n",
    "    elif 'Gpt' in dictWithTranslatedColumnName.keys():\n",
    "        dictWithTranslatedColumnName['Gpt'].append(gptTranslatedColumnName)\n",
    "    \n",
    "    for ollamaModelName in ollamaModels:\n",
    "        ollamaTranslatedColumnName = removeTextInParentheses(meltemiTranslateInfo(f'{systemContent} \\n {prompt}', ollamaModelName))\n",
    "        if ollamaModelName not in dictWithTranslatedColumnName.keys():\n",
    "            dictWithTranslatedColumnName[ollamaModelName] = [ollamaTranslatedColumnName]\n",
    "        elif ollamaModelName in dictWithTranslatedColumnName.keys():\n",
    "            dictWithTranslatedColumnName[ollamaModelName].append(ollamaTranslatedColumnName)\n",
    "\n",
    "    count +=1 # TODO Remove Count\n",
    "    if count == 5: # TODO Remove Count\n",
    "        break # TODO Remove Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame has been written to Column Translate Evaluation.xlsx successfully.\n"
     ]
    }
   ],
   "source": [
    "columnsDf = pd.DataFrame(dictWithTranslatedColumnName)\n",
    "# Add prefix to column names\n",
    "prefix = 'column_names_translated_'\n",
    "columnsDf.columns = [prefix + col for col in columnsDf.columns]\n",
    "\n",
    "columnsDf['db_id'] = listWithDbId[:5] # TODO Remove the limit\n",
    "columnsDf['table_id'] = listWithTableIdForColumnName[:5] # TODO Remove the limit\n",
    "columnsDf['table_name'] = listWithTableNamesForColumnName[:5] # TODO Remove the limit\n",
    "columnsDf['column_names_original'] = listWithColumnNameOriginalPerDbId[:5] # TODO Remove the limit\n",
    "columnsDf['column_names_translated'] = ''\n",
    "\n",
    "# Define the new column order with \"db_id\" first and \"table_names_original\" second\n",
    "newColumnOrder = ['db_id', 'table_id', 'table_name', 'column_names_original'] + [col for col in columnsDf.columns if col not in ['db_id', 'table_id', 'table_name', 'column_names_original']]\n",
    "\n",
    "# Change the order of columns using reindex\n",
    "columnsDf = columnsDf.reindex(columns=newColumnOrder)\n",
    "\n",
    "# Define the output file name for the Excel file\n",
    "columnOutputFileName = 'Column Translate Evaluation.xlsx'\n",
    "\n",
    "# Write the DataFrame to an Excel file without including the index\n",
    "columnsDf.to_excel(columnOutputFileName, index=False)\n",
    "\n",
    "# Print a confirmation message indicating successful writing of the DataFrame to the Excel file\n",
    "print(f\"DataFrame has been written to {columnOutputFileName} successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating a DataFrame with four columns: db_id, table_id, column_names_original, and column_names_translated\n",
    "# columnsDf = pd.DataFrame({\n",
    "#     'db_id': listWithDbId,\n",
    "#     'table_id': listWithTableIdForColumnName,\n",
    "#     'table_name': listWithTableNamesForColumnName,\n",
    "#     'column_names_original': listWithColumnNameOriginalPerDbId,\n",
    "#     'column_names_translated': listWithTranslatedColumnName\n",
    "# })\n",
    "\n",
    "# # Define the output file name for the Excel file\n",
    "# columnOutputFileName = 'Column Translate Evaluation.xlsx'\n",
    "\n",
    "# # Write the DataFrame to an Excel file without including the index\n",
    "# columnsDf.to_excel(columnOutputFileName, index=False)\n",
    "\n",
    "# # Print a confirmation message indicating successful writing of the DataFrame to the Excel file\n",
    "# print(f\"DataFrame has been written to {columnOutputFileName} successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['column_names', 'column_names_original', 'column_types', 'db_id', 'foreign_keys', 'primary_keys', 'table_names', 'table_names_original', 'table_names_translated'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tablesData[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the DataFrame containing translated column names from the Excel file\n",
    "columnsDf = pd.read_excel(columnOutputFileName)\n",
    "\n",
    "# Initialize lists to store translated column names, table IDs, and column info\n",
    "listWithTranslatedColumnName = []\n",
    "listWithTableIdForColumnName = []\n",
    "listWithColumnInfo = []\n",
    "\n",
    "# Add the translated column names to the original data\n",
    "for database in tablesData:\n",
    "    # Extract the db_id of the current database\n",
    "    dbId = database['db_id']\n",
    "    \n",
    "    # Fetch the table IDs and translated column names for the current db_id from columnsDf\n",
    "    listWithTableIdForColumnName = fetchSpecificColumnForDbId(columnsDf, dbId, 'table_id')\n",
    "    listWithTranslatedColumnName = fetchSpecificColumnForDbId(columnsDf, dbId, 'column_names_translated')\n",
    "    \n",
    "    # Iterate over the translated column names and table IDs\n",
    "    for i in range(len(listWithTranslatedColumnName)):\n",
    "        # Append the table ID and translated column name as a list to listWithColumnInfo\n",
    "        listWithColumnInfo.append([listWithTableIdForColumnName[i], listWithTranslatedColumnName[i]])\n",
    "    \n",
    "    # Assign the listWithColumnInfo to the 'column_names_translated' key in the original database data\n",
    "    database['column_names_translated'] = listWithColumnInfo\n",
    "    \n",
    "    break #TODO: Remove the break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'column_names': [[-1, '*'],\n",
       "  [0, 'perpetrator id'],\n",
       "  [0, 'people id'],\n",
       "  [0, 'date'],\n",
       "  [0, 'year'],\n",
       "  [0, 'location'],\n",
       "  [0, 'country'],\n",
       "  [0, 'killed'],\n",
       "  [0, 'injured'],\n",
       "  [1, 'people id'],\n",
       "  [1, 'name'],\n",
       "  [1, 'height'],\n",
       "  [1, 'weight'],\n",
       "  [1, 'home town']],\n",
       " 'column_names_original': [[-1, '*'],\n",
       "  [0, 'Perpetrator_ID'],\n",
       "  [0, 'People_ID'],\n",
       "  [0, 'Date'],\n",
       "  [0, 'Year'],\n",
       "  [0, 'Location'],\n",
       "  [0, 'Country'],\n",
       "  [0, 'Killed'],\n",
       "  [0, 'Injured'],\n",
       "  [1, 'People_ID'],\n",
       "  [1, 'Name'],\n",
       "  [1, 'Height'],\n",
       "  [1, 'Weight'],\n",
       "  [1, 'Home Town']],\n",
       " 'column_types': ['text',\n",
       "  'number',\n",
       "  'number',\n",
       "  'text',\n",
       "  'number',\n",
       "  'text',\n",
       "  'text',\n",
       "  'number',\n",
       "  'number',\n",
       "  'number',\n",
       "  'text',\n",
       "  'number',\n",
       "  'number',\n",
       "  'text'],\n",
       " 'db_id': 'perpetrator',\n",
       " 'foreign_keys': [[2, 9]],\n",
       " 'primary_keys': [1, 9],\n",
       " 'table_names': ['perpetrator', 'people'],\n",
       " 'table_names_original': ['perpetrator', 'people'],\n",
       " 'table_names_translated': [nan, nan],\n",
       " 'column_names_translated': [[-1, nan],\n",
       "  [0, nan],\n",
       "  [0, nan],\n",
       "  [0, nan],\n",
       "  [0, nan]]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tablesData[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the updated tables.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate dev.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['column_names', 'column_names_original', 'column_types', 'db_id', 'foreign_keys', 'primary_keys', 'table_names', 'table_names_original'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the tables.json\n",
    "tableFileName = r'..\\Spider\\tables.json'\n",
    "tablesData = loadJson(tableFileName)\n",
    "tablesData[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['db_id', 'query', 'query_toks', 'query_toks_no_value', 'question', 'question_toks', 'sql'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dev.json\n",
    "devFileName = r'..\\Spider\\dev.json'\n",
    "devDataset = loadJson(devFileName)\n",
    "devDataset[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictWithTablesData = {}\n",
    "\n",
    "# Create a dictionary where db_id is the key and the corresponding jsonSchema is the value\n",
    "for jsonSchema in tablesData:\n",
    "    dictWithTablesData[jsonSchema['db_id']] = jsonSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTableDict(database):\n",
    "    dictWithTables = {}\n",
    "    # Extract table names from the database schema (assuming they are stored in 'table_names')\n",
    "    tablesNames = database['table_names']  # TODO: Change to 'table_names_translated' once available\n",
    "    \n",
    "    # Iterate over the table names and assign each a unique index as the key in the dictionary\n",
    "    for index, tableName in enumerate(tablesNames):\n",
    "        dictWithTables[index] = tableName\n",
    "    \n",
    "    return dictWithTables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnTableAndColumnInfoForDbId(dictWithTablesData, dbId):\n",
    "    # Retrieve the database schema corresponding to the given dbId\n",
    "    database = dictWithTablesData[dbId]\n",
    "    # Create a dictionary of tables with their indices as keys\n",
    "    dictWithTables = createTableDict(database)\n",
    "\n",
    "    # Initialize a list to store table and column information\n",
    "    listWithTableAndColumnInfo = []\n",
    "\n",
    "    # Iterate over the column information in the database schema\n",
    "    for index, columnName in database['column_names']:  # TODO: Change to 'column_names_translated' once available\n",
    "        # Check if the column index is valid (-1 indicates unknown)\n",
    "        if index != -1:\n",
    "            # Retrieve the table name corresponding to the index from the dictionary\n",
    "            tableName = dictWithTables[index]\n",
    "            # Append the table name and column name to the list\n",
    "            listWithTableAndColumnInfo.append([tableName, columnName])\n",
    "\n",
    "    return listWithTableAndColumnInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSchemaInfoDict(listWithTableAndColumnInfo):\n",
    "    # Create an empty dictionary to store table names as keys and corresponding column names as values.\n",
    "    dictWithSchemaInfo = {}\n",
    "\n",
    "    # Iterate through pairs of table names and column names.\n",
    "    for tableName, columnName in listWithTableAndColumnInfo:\n",
    "        # Check if both the table name and column name are not special values.\n",
    "        if tableName != -1 and columnName != '*':\n",
    "            # Check if the table name is not already in the dictionary.\n",
    "            if tableName not in dictWithSchemaInfo.keys():\n",
    "                # If not, initialize the entry with a list containing the current column name.\n",
    "                dictWithSchemaInfo[tableName] = [columnName]\n",
    "            else:\n",
    "                # If the table name is already in the dictionary, append the current column name to its list of column names.\n",
    "                dictWithSchemaInfo[tableName].append(columnName)\n",
    "    return dictWithSchemaInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTheDesiredPromtForQuestionsTranslation(question, dictWithSchemaInfo):\n",
    "    infoString = \"\"\n",
    "\n",
    "    for tableName, columnNames in dictWithSchemaInfo.items():\n",
    "        infoString += f\"Table: {tableName}\\n\"\n",
    "        infoString += f\"Columns: {', '.join(columnNames)}\\n\"\n",
    "    \n",
    "    return f'''Translate the question \"{question}\" to Greek. You can only use keywords provided below:\\n{infoString}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "listWithDbId = []\n",
    "listWithOriginalQuestionPerDbId = []\n",
    "dictWithTranslatedQuestionPerDbId = {}\n",
    "listWithTableAndColumnInfoForQuestion = []\n",
    "\n",
    "systemContent = 'I will give you english questions and you will translate it to greek. Please return only the translated question.'\n",
    "\n",
    "count = 0 # TODO Remove Count\n",
    "# Iterate over each questionInfo in devDataset\n",
    "for questionInfo in devDataset:\n",
    "    # Extract the db_id from the questionInfo\n",
    "    dbId = questionInfo['db_id']\n",
    "    # Append the dbId to listWithDbId\n",
    "    listWithDbId.append(dbId)\n",
    "    # Retrieve table and column information for the current dbId\n",
    "    listWithTableAndColumnInfo = returnTableAndColumnInfoForDbId(dictWithTablesData, dbId)\n",
    "    dictWithSchemaInfo = createSchemaInfoDict(listWithTableAndColumnInfo)\n",
    "    # Append the table and column information to listWithTableAndColumnInfoForQuestion\n",
    "    listWithTableAndColumnInfoForQuestion.append(listWithTableAndColumnInfo)\n",
    "    # Extract the original question from questionInfo and append it to listWithOriginalQuestionPerDbId\n",
    "    question = questionInfo['question']\n",
    "    listWithOriginalQuestionPerDbId.append(question)\n",
    "\n",
    "    prompt = createTheDesiredPromtForQuestionsTranslation(question, dictWithSchemaInfo)\n",
    "\n",
    "    # Translate the question \n",
    "    GptTranslatedQuestion = removeTextInParentheses(gptTranslateInfo(systemContent, prompt))\n",
    "    if 'Gpt' not in dictWithTranslatedQuestionPerDbId.keys():\n",
    "        dictWithTranslatedQuestionPerDbId['Gpt'] = [GptTranslatedQuestion]\n",
    "    elif 'Gpt' in dictWithTranslatedQuestionPerDbId.keys():\n",
    "        dictWithTranslatedQuestionPerDbId['Gpt'].append(GptTranslatedQuestion)\n",
    "    \n",
    "    for ollamaModelName in ollamaModels:\n",
    "        ollamaTranslatedQuestion = removeTextInParentheses(meltemiTranslateInfo(f'{systemContent} \\n {prompt}', ollamaModelName))\n",
    "        if ollamaModelName not in dictWithTranslatedQuestionPerDbId.keys():\n",
    "            dictWithTranslatedQuestionPerDbId[ollamaModelName] = [ollamaTranslatedQuestion]\n",
    "        elif ollamaModelName in dictWithTranslatedQuestionPerDbId.keys():\n",
    "            dictWithTranslatedQuestionPerDbId[ollamaModelName].append(ollamaTranslatedQuestion)\n",
    "\n",
    "    count +=1 # TODO Remove Count\n",
    "    if count == 5: # TODO Remove Count\n",
    "        break # TODO Remove Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame has been written to Question Translate Evaluation.xlsx successfully.\n"
     ]
    }
   ],
   "source": [
    "questionsDf = pd.DataFrame(dictWithTranslatedQuestionPerDbId)\n",
    "# Add prefix to column names\n",
    "prefix = 'question_translated_'\n",
    "questionsDf.columns = [prefix + col for col in questionsDf.columns]\n",
    "\n",
    "questionsDf['db_id'] = listWithDbId[:1] # TODO Remove the limit\n",
    "questionsDf['table_info'] = listWithTableAndColumnInfoForQuestion[:1] # TODO Remove the limit\n",
    "questionsDf['question_original'] = listWithOriginalQuestionPerDbId[:1] # TODO Remove the limit\n",
    "questionsDf['question_translated'] = ''\n",
    "\n",
    "# Define the new column order with \"db_id\" first and \"table_names_original\" second\n",
    "newColumnOrder = ['db_id', 'table_info', 'question_original'] + [col for col in questionsDf.columns if col not in ['db_id', 'table_info', 'question_original']]\n",
    "\n",
    "# Change the order of columns using reindex\n",
    "questionsDf = questionsDf.reindex(columns=newColumnOrder)\n",
    "\n",
    "# Define the output file name for the Excel file\n",
    "questionsOutputFileName = 'Question Translate Evaluation.xlsx'\n",
    "\n",
    "# Write the DataFrame to an Excel file without including the index\n",
    "questionsDf.to_excel(questionsOutputFileName, index=False)\n",
    "\n",
    "# Print a confirmation message indicating successful writing of the DataFrame to the Excel file\n",
    "print(f\"DataFrame has been written to {questionsOutputFileName} successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating a DataFrame with four columns: db_id, table_info, question_original, and question_translated\n",
    "# questionsDf = pd.DataFrame({\n",
    "#     'db_id': listWithDbId,\n",
    "#     'table_info': listWithTableAndColumnInfoForQuestion,\n",
    "#     'question_original': listWithOriginalQuestionPerDbId,\n",
    "#     'question_translated': listWithTranslatedQuestionPerDbId\n",
    "# })\n",
    "\n",
    "# # Define the output file name for the Excel file\n",
    "# questionsOutputFileName = 'Question Translate Evaluation.xlsx'\n",
    "\n",
    "# # Write the DataFrame to an Excel file without including the index\n",
    "# questionsDf.to_excel(questionsOutputFileName, index=False)\n",
    "\n",
    "# # Print a confirmation message indicating successful writing of the DataFrame to the Excel file\n",
    "# print(f\"DataFrame has been written to {questionsOutputFileName} successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add question tokens to final json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def tokenizeSentence(sentence):\n",
    "    # Tokenize the input sentence using nltk.word_tokenize()\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the final question DataFrame from the Excel file\n",
    "questionsDf = pd.read_excel(questionsOutputFileName)\n",
    "\n",
    "# Add the translated question and its tokenized form to the original data\n",
    "for questionInfo in devDataset:\n",
    "    # Extract the db_id and original question from the questionInfo\n",
    "    dbId = questionInfo['db_id']\n",
    "    question = questionInfo['question']\n",
    "    \n",
    "    # Filter questionsDf to find the row corresponding to the current dbId and original question\n",
    "    filteredQuestionsDf = questionsDf[(questionsDf['db_id'] == dbId) & (questionsDf['question_original'] == question)]\n",
    "    \n",
    "    # Extract the translated question from the filtered DataFrame\n",
    "    questionTranslated = filteredQuestionsDf['question_translated'].values[0]\n",
    "    \n",
    "    # Update questionInfo with the translated question and its tokenized form\n",
    "    questionInfo['question_translated'] = questionTranslated\n",
    "    questionInfo['question_toks_translated'] = tokenizeSentence(questionTranslated)\n",
    "    \n",
    "    break #TODO: Remove the break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devDataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the updated dev.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
