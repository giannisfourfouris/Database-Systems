{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate tables.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Define a function to load JSON data from a file\n",
    "def loadJson(filename):\n",
    "    # Open the specified file in read mode, specifying utf-8 encoding\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        # Load the JSON data from the file into a Python dictionary\n",
    "        data = json.load(file)\n",
    "    # Return the loaded data\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeJsonToFile(data, filePath, indent=4):\n",
    "    with open(filePath, \"w\", encoding=\"utf-8\") as jsonFile:\n",
    "        json.dump(data, jsonFile, ensure_ascii=False, indent=indent)\n",
    "\n",
    "    print(\"JSON data written to\", filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def fetchSpecificColumnForDbId(df, specificDbId, columnName):\n",
    "    # Filter rows based on the specific db_id\n",
    "    filteredDf = df[df['db_id'] == specificDbId]\n",
    "\n",
    "    # Extract the specified column from the filtered DataFrame\n",
    "    column_data = filteredDf[columnName]\n",
    "\n",
    "    # Convert the column data to a list\n",
    "    column_list = column_data.tolist()\n",
    "\n",
    "    return column_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTableDict(database):\n",
    "    dictWithTables = {}\n",
    "    # Extract table names from the database schema (assuming they are stored in 'table_names')\n",
    "    tablesNames = database['table_names_translated']\n",
    "    \n",
    "    # Iterate over the table names and assign each a unique index as the key in the dictionary\n",
    "    for index, tableName in enumerate(tablesNames):\n",
    "        dictWithTables[index] = tableName\n",
    "    \n",
    "    return dictWithTables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def removeTextInParentheses(inputString):\n",
    "    # Define a regex pattern to match text within parentheses\n",
    "    pattern = r'\\([^)]*\\)'\n",
    "    \n",
    "    # Use re.sub() to replace the matched pattern with an empty string\n",
    "    outputString = re.sub(pattern, '', inputString)\n",
    "    \n",
    "    return outputString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capitalizeFirstLetter(word):\n",
    "    # Check if the word is not empty\n",
    "    if word:\n",
    "        # Capitalize the first letter\n",
    "        capitalizedWord = word[0].upper() + word[1:]\n",
    "        return capitalizedWord\n",
    "    else:\n",
    "        return word\n",
    "    \n",
    "def removeUnnecessarySpaces(inputString):\n",
    "    # Remove leading and trailing spaces\n",
    "    inputString = inputString.strip()\n",
    "    \n",
    "    # Remove extra spaces between words\n",
    "    inputString = \" \".join(inputString.split())\n",
    "    \n",
    "    return inputString\n",
    "\n",
    "def isAllUppercase(s):\n",
    "    return s.isupper()\n",
    "\n",
    "def makeLower(s):\n",
    "    return s.lower()\n",
    "\n",
    "def splitAndJoin(inputString):\n",
    "    if inputString in ('*'):\n",
    "        return inputString\n",
    "    \n",
    "    if isAllUppercase(inputString):\n",
    "        inputString = makeLower(inputString)\n",
    "    \n",
    "\n",
    "    # Convert the input string to lowercase\n",
    "    inputString = capitalizeFirstLetter(inputString)\n",
    "    \n",
    "    # Split the input string based on underscores\n",
    "    splitStringsUnderscore = re.split(r'_', inputString)\n",
    "    \n",
    "    joinedString = ' '.join(splitStringsUnderscore)\n",
    "    \n",
    "    splitStringsCapital = re.findall('[Α-ΩΆ-Ώ][^Α-ΩΆ-Ώ]*', joinedString)\n",
    "\n",
    "    if not splitStringsCapital:\n",
    "        splitStringsCapital = splitStringsUnderscore\n",
    "    \n",
    "    # Join the split strings with spaces and convert to lowercase\n",
    "    joinedString = ' '.join(splitStringsCapital).lower()\n",
    "    return removeUnnecessarySpaces(joinedString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import Client\n",
    "\n",
    "def meltemiTranslateInfo(prompt, modelName):\n",
    "  client = Client(host='http://10.8.11.209:11434')\n",
    "  response = client.chat(model= modelName, messages=[\n",
    "    {\n",
    "      'role': 'user',\n",
    "      'content': prompt\n",
    "    },\n",
    "  ])\n",
    "  return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def gptTranslateInfo(systemContent, inputInfo): \n",
    "    openai.api_base = 'https://pta-nbg-poc1.openai.azure.com/'\n",
    "    openai.api_key = '89423897cfd94a89838586e836d26690'\n",
    "    deployment_name = 'got-35-turbo1'\n",
    "    openai.api_type = 'azure'\n",
    "    openai.api_version = '2023-03-15-preview' # this may change in the future\n",
    "\n",
    "    # systemContent = '''I will give you english column names from tables in english and you will translate it in greek. \n",
    "    # Please return only the translated column.'''\n",
    "\n",
    "    # inputInfo = '''Translate the column \"assets in million\" to greek to fit the context of the table:\n",
    "    # Table: company\n",
    "    # Columns: company id, name, headquarters, industry, sales in million, assets in million'''\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            engine=deployment_name, # The deployment name you chose when you deployed the GPT-3.5-Turbo or GPT-4 model.\n",
    "            temperature=0.3,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": systemContent},\n",
    "                {\"role\": \"user\", \"content\": inputInfo}\n",
    "            ]\n",
    "        )\n",
    "        return response['choices'][0]['message']['content']\n",
    "    except KeyError:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollamaModels = []#['meltemiUpdated', 'llama3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['column_names', 'column_names_original', 'column_types', 'db_id', 'foreign_keys', 'primary_keys', 'table_names', 'table_names_original'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the tables.json\n",
    "tableFileName = r'..\\Spider\\tables.json'\n",
    "tablesData = loadJson(tableFileName)\n",
    "tablesData[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "listWithDbId = []\n",
    "listWithTableNameOriginalPerDbId = []\n",
    "\n",
    "# Iterate over each database in tablesData\n",
    "for database in tablesData:\n",
    "    # Extract the db_id of the current database\n",
    "    dbId = database['db_id']\n",
    "    # Extract the table_names_original from the current database\n",
    "    tableNamesOriginal = database['table_names_original']\n",
    "    \n",
    "    # Iterate over each tableNameOriginal in tableNamesOriginal\n",
    "    for tableNameOriginal in tableNamesOriginal:\n",
    "        # Append the dbId to listWithDbId\n",
    "        listWithDbId.append(dbId)\n",
    "        # Append the tableNameOriginal to listWithTableNameOriginalPerDbId\n",
    "        listWithTableNameOriginalPerDbId.append(tableNameOriginal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('BackUp/translatedTables624.json', 'r') as f:\n",
    "#     dictWithTranslatedTableName  = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/876 of table names examined.\n",
      "174/876 of table names examined.\n",
      "261/876 of table names examined.\n",
      "348/876 of table names examined.\n",
      "435/876 of table names examined.\n",
      "522/876 of table names examined.\n",
      "609/876 of table names examined.\n",
      "696/876 of table names examined.\n",
      "783/876 of table names examined.\n",
      "870/876 of table names examined.\n"
     ]
    }
   ],
   "source": [
    "dictWithTranslatedTableName = {}\n",
    "\n",
    "systemContent = 'I will give you table names from a schema in english and you will translate it to greek. Please return only the translated table name.'\n",
    "\n",
    "totalNumOfTableNames = len(listWithTableNameOriginalPerDbId)\n",
    "percent = int(totalNumOfTableNames * 0.1 )  # Calculate 10% of the total tables\n",
    "\n",
    "# Iterate over each tableName in listWithTableNameOriginalPerDbId\n",
    "for index, tableName in enumerate(listWithTableNameOriginalPerDbId, start=1):\n",
    "    # Call the function to translate the tableName\n",
    "    gptTranslatedTableName = removeTextInParentheses(gptTranslateInfo(systemContent, tableName))\n",
    "    if 'Gpt' not in dictWithTranslatedTableName.keys():\n",
    "        dictWithTranslatedTableName['Gpt'] = [gptTranslatedTableName]\n",
    "    elif 'Gpt' in dictWithTranslatedTableName.keys():\n",
    "        dictWithTranslatedTableName['Gpt'].append(gptTranslatedTableName)\n",
    "    \n",
    "    for ollamaModelName in ollamaModels:\n",
    "        ollamaTranslatedTableName = removeTextInParentheses(meltemiTranslateInfo(f'{systemContent} \\n {tableName}', ollamaModelName))\n",
    "        if ollamaModelName not in dictWithTranslatedTableName.keys():\n",
    "            dictWithTranslatedTableName[ollamaModelName] = [ollamaTranslatedTableName]\n",
    "        elif ollamaModelName in dictWithTranslatedTableName.keys():\n",
    "            dictWithTranslatedTableName[ollamaModelName].append(ollamaTranslatedTableName)\n",
    "    \n",
    "    if index % percent == 0:\n",
    "        # Writing dictionary to a file\n",
    "        with open(f'BackUp/translatedTables{len(dictWithTranslatedTableName[\"Gpt\"])}.json', 'w') as f:\n",
    "            json.dump(dictWithTranslatedTableName, f)\n",
    "        print(f\"{index}/{totalNumOfTableNames} of table names examined.\")\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablesDf = pd.DataFrame(dictWithTranslatedTableName)\n",
    "# Add prefix to column names\n",
    "prefix = 'table_names_original_translated_'\n",
    "tablesDf.columns = [prefix + col for col in tablesDf.columns]\n",
    "\n",
    "tablesDf['db_id'] = listWithDbId\n",
    "tablesDf['table_names_original'] = listWithTableNameOriginalPerDbId\n",
    "tablesDf['table_names_original_translated'] = ''\n",
    "\n",
    "# Define the new column order with \"db_id\" first and \"table_names_original\" second\n",
    "newColumnOrder = ['db_id', 'table_names_original'] + [col for col in tablesDf.columns if col not in ['db_id', 'table_names_original']]\n",
    "\n",
    "# Change the order of columns using reindex\n",
    "tablesDf = tablesDf.reindex(columns=newColumnOrder)\n",
    "\n",
    "# Define the output file name for the Excel file\n",
    "tableOutputFileName = 'Translation/Table Translate Evaluation.xlsx'\n",
    "\n",
    "# Write the DataFrame to an Excel file without including the index\n",
    "tablesDf.to_excel(tableOutputFileName, index=False)\n",
    "\n",
    "# Print a confirmation message indicating successful writing of the DataFrame to the Excel file\n",
    "print(f\"DataFrame has been written to {tableOutputFileName} successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the final table name DataFrame from the Excel file\n",
    "tableOutputFileName = 'Translation/Table Translate Evaluation.xlsx'\n",
    "tablesDf = pd.read_excel(tableOutputFileName)\n",
    "\n",
    "# Add the translated table names to the original data\n",
    "for database in tablesData:\n",
    "    # Extract the db_id of the current database\n",
    "    dbId = database['db_id']\n",
    "    # Fetch the translated table names for the current db_id from tablesDf\n",
    "    translatedTableNamesOriginal = fetchSpecificColumnForDbId(tablesDf, dbId, 'table_names_original_translated')\n",
    "\n",
    "    listWithTablesNamesTranslated = []\n",
    "    for tableName in translatedTableNamesOriginal:\n",
    "        curatedTableName = splitAndJoin(tableName)\n",
    "        if curatedTableName != '':\n",
    "            listWithTablesNamesTranslated.append(curatedTableName)\n",
    "        else:\n",
    "            raise ValueError(f'Curated Table Name for {tableName} should not be empty')\n",
    "        \n",
    "    # Assign the translated table names to the 'table_names_translated' key in the original database data\n",
    "    database['table_names_original_translated'] = translatedTableNamesOriginal\n",
    "    database['table_names_translated'] = listWithTablesNamesTranslated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data written to translatedTableNames.json\n"
     ]
    }
   ],
   "source": [
    "#Save the tables.json as it contains the translated table_names\n",
    "translatedTableNamesPath = 'translatedTableNames.json'\n",
    "writeJsonToFile(tablesData, translatedTableNamesPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the translatedTableNames.json\n",
    "translatedTableNamesPath = 'translatedTableNames.json'\n",
    "tableFileName = translatedTableNamesPath\n",
    "tablesData = loadJson(tableFileName)\n",
    "tablesData[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "listWithDbId = []\n",
    "listWithColumnNameOriginalPerDbId = []\n",
    "listWithTableIdForColumnName = []\n",
    "listWithTableNamesForColumnName = []\n",
    "\n",
    "# Iterate over each database in tablesData\n",
    "for database in tablesData:\n",
    "    # Extract the db_id of the current database\n",
    "    dbId = database['db_id']\n",
    "\n",
    "    # Create a dictionary of tables with their indices as keys\n",
    "    dictWithTables = createTableDict(database)\n",
    "    \n",
    "    # Iterate over each columnNameInfo in column_names_original of the current database\n",
    "    for columnNameInfo in database['column_names_original']:\n",
    "\n",
    "        # Append the dbId to listWithDbId\n",
    "        listWithDbId.append(dbId)\n",
    "        \n",
    "        # Extract the columnNameOriginal from columnNameInfo and append it to listWithColumnNameOriginalPerDbId\n",
    "        columnNameOriginal = columnNameInfo[1]\n",
    "        listWithColumnNameOriginalPerDbId.append(columnNameOriginal)\n",
    "        \n",
    "        # Extract the tableId from columnNameInfo and append it to listWithTableIdForColumnName\n",
    "        tableId = columnNameInfo[0]\n",
    "        listWithTableIdForColumnName.append(tableId)\n",
    "\n",
    "        # If tableId is -1, append '-1' to listWithTableNamesForColumnName, indicating unknown table\n",
    "        if tableId == -1:\n",
    "            listWithTableNamesForColumnName.append('-1')\n",
    "        else:\n",
    "            # Otherwise, append the table name corresponding to tableId to listWithTableNamesForColumnName\n",
    "            listWithTableNamesForColumnName.append(dictWithTables[tableId])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictionary to store table names as keys and corresponding column names as values.\n",
    "dictWitnTablesAndColumnsNames = {}\n",
    "\n",
    "# Iterate through pairs of table names and column names.\n",
    "for tableName, columnName in zip(listWithTableNamesForColumnName, listWithColumnNameOriginalPerDbId):\n",
    "    # Check if the table name is not already in the dictionary.\n",
    "    if tableName not in dictWitnTablesAndColumnsNames.keys():\n",
    "        # If not, initialize the entry with a list containing the current column name.\n",
    "        dictWitnTablesAndColumnsNames[tableName] = [columnName]\n",
    "    else:\n",
    "        # If the table name is already in the dictionary, append the current column name to its list of column names.\n",
    "        dictWitnTablesAndColumnsNames[tableName].append(columnName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTheDesiredPromtForColumnsTranslation(tableName, dictWitnTablesAndColumnsNames, columnName):\n",
    "    # Retrieve the list of column names associated with the given table name.\n",
    "    columnsInfo = dictWitnTablesAndColumnsNames[tableName]\n",
    "\n",
    "    # Join the list of column names into a comma-separated string.\n",
    "    columnCombination = ', '.join(columnsInfo)\n",
    "    \n",
    "    # Construct and return the prompt string for translating the given column name to Greek.\n",
    "    return f'''Translate the column \"{columnName}\" to Greek to fit the context of the table:\n",
    "            Table: {tableName}\n",
    "            Columns: {columnCombination}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/461 of column names examined.\n",
      "92/461 of column names examined.\n",
      "138/461 of column names examined.\n",
      "184/461 of column names examined.\n",
      "230/461 of column names examined.\n",
      "276/461 of column names examined.\n",
      "322/461 of column names examined.\n",
      "368/461 of column names examined.\n",
      "414/461 of column names examined.\n",
      "460/461 of column names examined.\n"
     ]
    }
   ],
   "source": [
    "dictWithTranslatedColumnName = {}\n",
    "\n",
    "systemContent = 'I will give you english column names from tables and you will translate it to greek. Please return only the translated column.'\n",
    "\n",
    "totalNumOfColumnNames = len(listWithColumnNameOriginalPerDbId)\n",
    "percent = int(totalNumOfColumnNames * 0.1)  # Calculate 1% of the total tables\n",
    "\n",
    "# Iterate over each columnName in listWithColumnNameOriginalPerDbId\n",
    "for index, (tableName, columnName) in enumerate(zip(listWithTableNamesForColumnName, listWithColumnNameOriginalPerDbId), start=1):\n",
    "    # Otherwise, call the function to translate the columnName\n",
    "    prompt = createTheDesiredPromtForColumnsTranslation(tableName, dictWitnTablesAndColumnsNames, columnName)\n",
    "    gptTranslatedColumnName = removeTextInParentheses(gptTranslateInfo(systemContent, prompt))\n",
    "    if 'Gpt' not in dictWithTranslatedColumnName.keys():\n",
    "        dictWithTranslatedColumnName['Gpt'] = [gptTranslatedColumnName]\n",
    "    elif 'Gpt' in dictWithTranslatedColumnName.keys():\n",
    "        dictWithTranslatedColumnName['Gpt'].append(gptTranslatedColumnName)\n",
    "    \n",
    "    for ollamaModelName in ollamaModels:\n",
    "        ollamaTranslatedColumnName = removeTextInParentheses(meltemiTranslateInfo(f'{systemContent} \\n {prompt}', ollamaModelName))\n",
    "        if ollamaModelName not in dictWithTranslatedColumnName.keys():\n",
    "            dictWithTranslatedColumnName[ollamaModelName] = [ollamaTranslatedColumnName]\n",
    "        elif ollamaModelName in dictWithTranslatedColumnName.keys():\n",
    "            dictWithTranslatedColumnName[ollamaModelName].append(ollamaTranslatedColumnName)\n",
    "\n",
    "    if index % percent == 0:\n",
    "        with open(f'BackUp/translatedColumns{len(dictWithTranslatedColumnName[\"Gpt\"])}.json', 'w') as f:\n",
    "            json.dump(dictWithTranslatedTableName, f)\n",
    "        print(f\"{index}/{totalNumOfColumnNames} of column names examined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame has been written to Column Translate Evaluation.xlsx successfully.\n"
     ]
    }
   ],
   "source": [
    "columnsDf = pd.DataFrame(dictWithTranslatedColumnName)\n",
    "# Add prefix to column names\n",
    "prefix = 'column_names_original_translated_'\n",
    "columnsDf.columns = [prefix + col for col in columnsDf.columns]\n",
    "\n",
    "columnsDf['db_id'] = listWithDbId\n",
    "columnsDf['table_id'] = listWithTableIdForColumnName\n",
    "columnsDf['table_name'] = listWithTableNamesForColumnName\n",
    "columnsDf['column_names_original'] = listWithColumnNameOriginalPerDbId\n",
    "columnsDf['column_names_original_translated'] = ''\n",
    "\n",
    "# Define the new column order with \"db_id\" first and \"table_names_original\" second\n",
    "newColumnOrder = ['db_id', 'table_id', 'table_name', 'column_names_original'] + [col for col in columnsDf.columns if col not in ['db_id', 'table_id', 'table_name', 'column_names_original']]\n",
    "\n",
    "# Change the order of columns using reindex\n",
    "columnsDf = columnsDf.reindex(columns=newColumnOrder)\n",
    "\n",
    "# Define the output file name for the Excel file\n",
    "columnOutputFileName = 'Translation/Column Translate Evaluation.xlsx'\n",
    "\n",
    "# Write the DataFrame to an Excel file without including the index\n",
    "columnsDf.to_excel(columnOutputFileName, index=False)\n",
    "\n",
    "# Print a confirmation message indicating successful writing of the DataFrame to the Excel file\n",
    "print(f\"DataFrame has been written to {columnOutputFileName} successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the DataFrame containing translated column names from the Excel file\n",
    "columnOutputFileName = 'Translation/Column Translate Evaluation.xlsx'\n",
    "columnsDf = pd.read_excel(columnOutputFileName)\n",
    "\n",
    "# Add the translated column names to the original data\n",
    "for database in tablesData:\n",
    "    # Extract the db_id of the current database\n",
    "    dbId = database['db_id']\n",
    "\n",
    "    # Initialize lists to store translated column names, table IDs, and column info\n",
    "    listWithTranslatedColumnName = []\n",
    "    listWithTableIdForColumnName = []\n",
    "    listWithColumnInfoOriginal = []\n",
    "    listWithColumnInfo = []\n",
    "\n",
    "    # Fetch the table IDs and translated column names for the current db_id from columnsDf\n",
    "    listWithTableIdForColumnName = fetchSpecificColumnForDbId(columnsDf, dbId, 'table_id')\n",
    "    print()\n",
    "    listWithTranslatedColumnName = fetchSpecificColumnForDbId(columnsDf, dbId, 'column_names_original_translated')\n",
    "    \n",
    "    # Iterate over the translated column names and table IDs\n",
    "    for i in range(len(listWithTranslatedColumnName)):\n",
    "        # Append the table ID and translated column name as a list to listWithColumnInfoOriginal\n",
    "        listWithColumnInfoOriginal.append([listWithTableIdForColumnName[i], listWithTranslatedColumnName[i]])\n",
    "\n",
    "        curatedColumnName = splitAndJoin(listWithTranslatedColumnName[i])\n",
    "        if curatedColumnName != '':\n",
    "            listWithColumnInfo.append([listWithTableIdForColumnName[i], curatedColumnName])\n",
    "        else:\n",
    "            raise ValueError(f'Curated Column Name for table {listWithTableIdForColumnName[i]} and Column {curatedColumnName} should not be empty')\n",
    "\n",
    "    # Assign the listWithColumnInfo to the 'column_names_translated' key in the original database data\n",
    "    database['column_names_original_translated'] = listWithColumnInfoOriginal\n",
    "    database['column_names_translated'] = listWithColumnInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for table in tablesData:\n",
    "    #table['table_names_original'] = table.pop('table_names_original_translated')\n",
    "    table['table_names'] = table.pop('table_names_translated')\n",
    "    #table['column_names_original'] = table.pop('column_names_original_translated')\n",
    "    table['column_names'] = table.pop('column_names_translated')\n",
    "    del table['table_names_original_translated']\n",
    "    del table['column_names_original_translated']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data written to translatedTableandColumnNames.json\n"
     ]
    }
   ],
   "source": [
    "#Save the updated translatedTableandColumnNames.json\n",
    "translatedTableandColumnNamesPath = 'translatedTableandColumnNames.json'\n",
    "writeJsonToFile(tablesData, 'translatedTableandColumnNames.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate dev.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translatedTableandColumnNamesPath = 'translatedTableandColumnNames.json'\n",
    "tableFileName = translatedTableandColumnNamesPath\n",
    "tablesData = loadJson(tableFileName)\n",
    "tablesData[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['db_id', 'query', 'query_toks', 'query_toks_no_value', 'question', 'question_toks', 'sql'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dev.json\n",
    "devFileName = r'..\\Spider\\dev.json'\n",
    "devDataset = loadJson(devFileName)\n",
    "devDataset[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictWithTablesData = {}\n",
    "\n",
    "# Create a dictionary where db_id is the key and the corresponding jsonSchema is the value\n",
    "for jsonSchema in tablesData:\n",
    "    dictWithTablesData[jsonSchema['db_id']] = jsonSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTableDict(database):\n",
    "    dictWithTables = {}\n",
    "    # Extract table names from the database schema (assuming they are stored in 'table_names')\n",
    "    tablesNames = database['table_names_translated']\n",
    "    \n",
    "    # Iterate over the table names and assign each a unique index as the key in the dictionary\n",
    "    for index, tableName in enumerate(tablesNames):\n",
    "        dictWithTables[index] = tableName\n",
    "    \n",
    "    return dictWithTables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnTableAndColumnInfoForDbId(dictWithTablesData, dbId):\n",
    "    # Retrieve the database schema corresponding to the given dbId\n",
    "    database = dictWithTablesData[dbId]\n",
    "    # Create a dictionary of tables with their indices as keys\n",
    "    dictWithTables = createTableDict(database)\n",
    "\n",
    "    # Initialize a list to store table and column information\n",
    "    listWithTableAndColumnInfo = []\n",
    "\n",
    "    # Iterate over the column information in the database schema\n",
    "    for index, columnName in database['column_names_translated']:\n",
    "        # Check if the column index is valid (-1 indicates unknown)\n",
    "        if index != -1:\n",
    "            # Retrieve the table name corresponding to the index from the dictionary\n",
    "            tableName = dictWithTables[index]\n",
    "            # Append the table name and column name to the list\n",
    "            listWithTableAndColumnInfo.append([tableName, columnName])\n",
    "\n",
    "    return listWithTableAndColumnInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSchemaInfoDict(listWithTableAndColumnInfo):\n",
    "    # Create an empty dictionary to store table names as keys and corresponding column names as values.\n",
    "    dictWithSchemaInfo = {}\n",
    "\n",
    "    # Iterate through pairs of table names and column names.\n",
    "    for tableName, columnName in listWithTableAndColumnInfo:\n",
    "        # Check if both the table name and column name are not special values.\n",
    "        if tableName != -1 and columnName != '*':\n",
    "            # Check if the table name is not already in the dictionary.\n",
    "            if tableName not in dictWithSchemaInfo.keys():\n",
    "                # If not, initialize the entry with a list containing the current column name.\n",
    "                dictWithSchemaInfo[tableName] = [columnName]\n",
    "            else:\n",
    "                # If the table name is already in the dictionary, append the current column name to its list of column names.\n",
    "                dictWithSchemaInfo[tableName].append(columnName)\n",
    "    return dictWithSchemaInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTheDesiredPromtForQuestionsTranslation(question, dictWithSchemaInfo):\n",
    "    infoString = \"\"\n",
    "\n",
    "    for tableName, columnNames in dictWithSchemaInfo.items():\n",
    "        infoString += f\"Table: {tableName}\\n\"\n",
    "        infoString += f\"Columns: {', '.join(columnNames)}\\n\"\n",
    "    \n",
    "    return f'''Translate the question \"{question}\" to Greek. You can only use keywords provided below:\\n{infoString}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the question \"How many singers do we have?\" to Greek. You can only use keywords provided below:\n",
      "Table: στάδιο\n",
      "Columns: αναγνωριστικό σταδίου, τοποθεσία, όνομα, χωρητικότητα, υψηλότερο, χαμηλότερο, μέσος όρος\n",
      "Table: τραγουδιστής\n",
      "Columns: αναγνωριστικό τραγουδιστή, όνομα, χώρα, όνομα τραγουδιού, έτος κυκλοφορίας τραγουδιού, ηλικία, είναι άνδρας\n",
      "Table: συναυλία\n",
      "Columns: αναγνωριστικό συναυλίας, όνομα συναυλίας, θέμα, αναγνωριστικό σταδίου, έτος\n",
      "Table: τραγουδιστής σε συναυλία\n",
      "Columns: αναγνωριστικό συναυλίας, αναγνωριστικό τραγουδιστή\n",
      "\n"
     ]
    }
   ],
   "source": [
    "listWithDbId = []\n",
    "listWithOriginalQuestionPerDbId = []\n",
    "dictWithTranslatedQuestionPerDbId = {}\n",
    "listWithTableAndColumnInfoForQuestion = []\n",
    "\n",
    "systemContent = 'I will give you english questions and you will translate it to greek. Please return only the translated question.'\n",
    "\n",
    "totalNumOfQuestions = len(devDataset)\n",
    "percent = int(totalNumOfQuestions * 0.1)  # Calculate 1% of the total tables\n",
    "\n",
    "# Iterate over each questionInfo in devDataset\n",
    "for index, questionInfo in enumerate(devDataset, start =1):\n",
    "    # Extract the db_id from the questionInfo\n",
    "    dbId = questionInfo['db_id']\n",
    "    # Append the dbId to listWithDbId\n",
    "    listWithDbId.append(dbId)\n",
    "    # Retrieve table and column information for the current dbId\n",
    "    listWithTableAndColumnInfo = returnTableAndColumnInfoForDbId(dictWithTablesData, dbId)\n",
    "    dictWithSchemaInfo = createSchemaInfoDict(listWithTableAndColumnInfo)\n",
    "    # Append the table and column information to listWithTableAndColumnInfoForQuestion\n",
    "    listWithTableAndColumnInfoForQuestion.append(listWithTableAndColumnInfo)\n",
    "    # Extract the original question from questionInfo and append it to listWithOriginalQuestionPerDbId\n",
    "    question = questionInfo['question']\n",
    "    listWithOriginalQuestionPerDbId.append(question)\n",
    "    \n",
    "    prompt = createTheDesiredPromtForQuestionsTranslation(question, dictWithSchemaInfo)\n",
    "    # Translate the question \n",
    "    GptTranslatedQuestion = removeTextInParentheses(gptTranslateInfo(systemContent, prompt))\n",
    "    if 'Gpt' not in dictWithTranslatedQuestionPerDbId.keys():\n",
    "        dictWithTranslatedQuestionPerDbId['Gpt'] = [GptTranslatedQuestion]\n",
    "    elif 'Gpt' in dictWithTranslatedQuestionPerDbId.keys():\n",
    "        dictWithTranslatedQuestionPerDbId['Gpt'].append(GptTranslatedQuestion)\n",
    "    \n",
    "    for ollamaModelName in ollamaModels:\n",
    "        ollamaTranslatedQuestion = removeTextInParentheses(meltemiTranslateInfo(f'{systemContent} \\n {prompt}', ollamaModelName))\n",
    "        if ollamaModelName not in dictWithTranslatedQuestionPerDbId.keys():\n",
    "            dictWithTranslatedQuestionPerDbId[ollamaModelName] = [ollamaTranslatedQuestion]\n",
    "        elif ollamaModelName in dictWithTranslatedQuestionPerDbId.keys():\n",
    "            dictWithTranslatedQuestionPerDbId[ollamaModelName].append(ollamaTranslatedQuestion)    \n",
    "\n",
    "    if index % percent == 0:\n",
    "        # Writing dictionary to a file\n",
    "        with open(f'BackUp/translatedQuestions{len(dictWithTranslatedQuestionPerDbId[\"Gpt\"])}.json', 'w') as f:\n",
    "            json.dump(dictWithTranslatedQuestionPerDbId, f)\n",
    "        print(f\"{index}/{totalNumOfQuestions} of questions have been examined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame has been written to Question Translate Evaluation.xlsx successfully.\n"
     ]
    }
   ],
   "source": [
    "questionsDf = pd.DataFrame(dictWithTranslatedQuestionPerDbId)\n",
    "# Add prefix to column names\n",
    "prefix = 'question_translated_'\n",
    "questionsDf.columns = [prefix + col for col in questionsDf.columns]\n",
    "\n",
    "questionsDf['db_id'] = listWithDbId\n",
    "questionsDf['table_info'] = listWithTableAndColumnInfoForQuestion\n",
    "questionsDf['question'] = listWithOriginalQuestionPerDbId\n",
    "questionsDf['question_translated'] = ''\n",
    "\n",
    "# Define the new column order with \"db_id\" first and \"table_names_original\" second\n",
    "newColumnOrder = ['db_id', 'table_info', 'question'] + [col for col in questionsDf.columns if col not in ['db_id', 'table_info', 'question']]\n",
    "\n",
    "# Change the order of columns using reindex\n",
    "questionsDf = questionsDf.reindex(columns=newColumnOrder)\n",
    "\n",
    "# Define the output file name for the Excel file\n",
    "questionsOutputFileName = 'Translation/Question Translate Evaluation.xlsx'\n",
    "\n",
    "# Write the DataFrame to an Excel file without including the index\n",
    "questionsDf.to_excel(questionsOutputFileName, index=False)\n",
    "\n",
    "# Print a confirmation message indicating successful writing of the DataFrame to the Excel file\n",
    "print(f\"DataFrame has been written to {questionsOutputFileName} successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add question tokens to final json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def tokenizeSentence(sentence):\n",
    "    # Tokenize the input sentence using nltk.word_tokenize()\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the final question DataFrame from the Excel file\n",
    "questionsOutputFileName = 'Translation/Question Translate Evaluation.xlsx'\n",
    "questionsDf = pd.read_excel(questionsOutputFileName)\n",
    "\n",
    "# Add the translated question and its tokenized form to the original data\n",
    "for questionInfo in devDataset:\n",
    "    # Extract the db_id and original question from the questionInfo\n",
    "    dbId = questionInfo['db_id']\n",
    "    question = questionInfo['question']\n",
    "    \n",
    "    # Filter questionsDf to find the row corresponding to the current dbId and original question\n",
    "    filteredQuestionsDf = questionsDf[(questionsDf['db_id'] == dbId) & (questionsDf['question'] == question)]\n",
    "    \n",
    "    # Extract the translated question from the filtered DataFrame\n",
    "    questionTranslated = filteredQuestionsDf['question_translated'].values[0]\n",
    "    \n",
    "    # Update questionInfo with the translated question and its tokenized form\n",
    "    questionInfo['question_translated'] = questionTranslated\n",
    "    questionInfo['question_toks_translated'] = tokenizeSentence(questionTranslated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for questionInfo in devDataset:\n",
    "    questionInfo['question'] = questionInfo.pop('question_translated')\n",
    "    questionInfo['question_toks'] = questionInfo.pop('question_toks_translated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data written to devGreek.json\n"
     ]
    }
   ],
   "source": [
    "#Save the updated dev.json\n",
    "writeJsonToFile(devDataset, 'devGreek.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
